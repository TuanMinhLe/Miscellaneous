{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Naive Bayes classifier with Parzen - Rosenblatt window method<\\center>\n",
    "\n",
    "Tuan Minh Le ([link to git repo]())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prettytable import PrettyTable\n",
    "import math as mt\n",
    "import numpy as np\n",
    "from numpy.linalg import inv, det\n",
    "from scipy.stats import multivariate_normal\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Consider a multidimensional recognition task with assumption that the feature vectors are $i.i.d$. Let $S = \\{x_1, x_2, \\dots, x_n\\}$ be a collection of $n$ observations and $C = \\{C_1, C_2, \\dots, C_N\\}$ be a set of $N$ classes.\n",
    "\n",
    "Let us recall the Bayes rule:\n",
    "\n",
    "$$Posteriori = P(C_i|x) = \\frac{P(x|C_i) \\cdot P(C_i)}{P(x)} = \\frac{Likelihood \\cdot Priori}{Evidence} \\text{ }\\text{ }\\text{ }\\text{ }\\text{ }(1).$$\n",
    "\n",
    "Giving a new vector $x$, a Bayes classifier will decide whether $x$ belongs to a particular class of $C$ by studying its posteriori probabilities, i.e. $x$ is classified into $C_i$ if $i = Argmax = \\{P(C_i|x)\\}$. Since $P(x)$ is equal for all classes, we can remove it from equation $(1)$ without affecting the decision process. The search for optimal solution now lies in the value of numerator.\n",
    "\n",
    "In the sections below, we will examine a method to compute these two probabilities. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute priori probabilities\n",
    "\n",
    "$P(C_i)$ refers to the expectation of how a new observation occuring before we actually see it. Thus, it is logical to define its value as follow:\n",
    "\n",
    "$$P(C_i)=\\frac{k_i}{n}$$\n",
    "\n",
    "where $k_i$ and $n$ are the number of samples classified in $C_i$ and the cardinality of the feature space, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_prior_probs(num_samples):\n",
    "    return [item / sum(num_samples) for item in num_samples]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimate likelihoods\n",
    "\n",
    "Normally, data from real - world issues are drawn from uncommon, mostly multimodal probability density. The idea to tackle this problem is to approximate $P(x|C_i)$ through some of $x$'s neighbors, whom we have known information about.\n",
    "\n",
    "**P**arzen - **R**osenblatt (**P** - **R**) window method, also known as **K**ernel **D**ensity **E**stimator (**KDE**), is a wide used non - parametric approach. It calculates **PDF** at $x$ by something called density function:\n",
    "\n",
    "$$P(x|C_i) \\approx \\hat{f}_h(x) = \\frac{1}{n} \\sum_{j=1}^n K_h (x-x_j) = \\frac{1}{n} \\sum_{j=1}^n K\\left(\\frac{x-x_j}{h}\\right)$$\n",
    "\n",
    "where:\n",
    "\n",
    "- $\\hat{f}_h(x)$ is the kernel function, which is a symmetric multivariate density.\n",
    "\n",
    "- $n$ is the number of samples in class $C_i$.\n",
    "\n",
    "- $h$ is the bandwidth of the kernel, which is a positive integer.\n",
    "\n",
    "The performance of estimator mainly depends on how we choose $\\hat{f}_h(x)$ and $h$. Due to Central limit theorem, most commonly Gaussian distribution is used for the kernel function. Picking the right value of bandwidth could be a challenging task, since we have no knowledge about the underlying density of the dataset. In practice, one should not set the same $h$ for every training space, but to examine different values then decide the best selection.\n",
    "\n",
    "**PDF** of $d$ - dimensional normal distribution:\n",
    "\n",
    "$$P(x) = \\frac{1}{(2\\pi)^{\\frac{d}{2}} |\\Sigma|^{\\frac{1}{2}}} exp\\left[\\frac{-1}{2} (x-\\mu)^T \\Sigma^{-1} (x-\\mu)\\right]$$\n",
    "\n",
    "where $\\mu$ is mean vector and $\\Sigma$ is covariance matrix.\n",
    "\n",
    "We then derive Gaussian kernel function as:\n",
    "\n",
    "$$K_h (x-x_j) = \\frac{1}{(2\\pi)^{\\frac{d}{2}} |\\Sigma|^{\\frac{1}{2}}} exp\\left[\\frac{-1}{2} (x-x_j)^T \\Sigma^{-1} (x-x_j)\\right].$$\n",
    "\n",
    "And then the approximate formula of $likelihood$:\n",
    "\n",
    "$$P(x|C_i) \\approx \\frac{1}{n (2\\pi)^\\frac{d}{2} |\\Sigma|^\\frac{1}{2}} \\sum_{j=1}^n exp\\left[\\frac{-1}{2} \\left(\\frac{x-x_j}{h}\\right)^T \\Sigma^{-1} \\left(\\frac{x-x_j}{h}\\right)\\right].$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_PR_estimate(x, h, dim, covariance, data):\n",
    "    PR_estimate = 0\n",
    "    for x_i in data:\n",
    "        n = len(data)\n",
    "        y = x - x_i\n",
    "        PR_estimate += mt.exp(\n",
    "            -0.5 * np.matmul(np.matmul(y / h, inv(covariance)), (y / h).T)\n",
    "        )\n",
    "        PR_estimate /= n * (2 * mt.pi) ** (dim / 2) * mt.sqrt(det(covariance))\n",
    "\n",
    "    return PR_estimate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on simulated data\n",
    "\n",
    "First, let us define some modules for data processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(dim, num_classes, num_samples, mean, covariance):\n",
    "    data = []\n",
    "    labels = []\n",
    "\n",
    "    for i in range(num_classes):\n",
    "        class_data = np.random.multivariate_normal(\n",
    "            mean[i].ravel(), covariance[i], num_samples[i]\n",
    "        )\n",
    "        for sample in class_data:\n",
    "            data.append(list(sample))\n",
    "\n",
    "        class_labels = i * np.ones(num_samples[i])\n",
    "        labels = np.append(labels, list(class_labels))\n",
    "\n",
    "    return np.array(data), labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_2d_visualize(data, labels, likelihood, num_classes, plot_paras):\n",
    "    x = [[] for i in range(num_classes)]\n",
    "    y = [[] for i in range(num_classes)]\n",
    "\n",
    "    for i in range(len(labels)):\n",
    "        j = int(labels[i])\n",
    "        x[j].append(data[i][0])\n",
    "        y[j].append(data[i][1])\n",
    "\n",
    "    fig = plt.figure(figsize=(12, 5))\n",
    "    fig.suptitle(plot_paras[0], size=15)\n",
    "\n",
    "    ax1 = fig.add_subplot(121)\n",
    "    for i in range(num_classes):\n",
    "        ax1.scatter(\n",
    "            x[i],\n",
    "            y[i],\n",
    "            marker=plot_paras[1][i],\n",
    "            color=plot_paras[2][i],\n",
    "            label=\"Class \" + str(i),\n",
    "        )\n",
    "\n",
    "    ax1.set_title(\"Samples\", size=10)\n",
    "    ax1.set_xlabel(\"$x$\", size=10)\n",
    "    ax1.set_ylabel(\"$y$\", size=10)\n",
    "    ax1.legend()\n",
    "\n",
    "    ax2 = fig.add_subplot(122, projection=\"3d\")\n",
    "    trisurf = ax2.plot_trisurf(\n",
    "        data[:, 0], data[:, 1], likelihood, cmap=\"jet\", edgecolor=\"none\",\n",
    "    )\n",
    "\n",
    "    ax2.set_title(\"Class conditional probabilities\", size=10)\n",
    "    ax2.set_xlabel(\"$x$\", size=10)\n",
    "    ax2.set_ylabel(\"$y$\", size=10)\n",
    "    ax2.set_zlabel(\"$P(x|C_i)$\", size=10)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For implementing the method, we will use a 2 - dimensional  random dataset from some bivariate normal distribution. Choosing $d=2$ allows us the luxury of visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 2\n",
    "num_classes = 4\n",
    "num_samples = [173, 154, 195, 127]\n",
    "mean = np.array([[-4.99, 6.78], [1.45, 9.8], [1.33, 4], [-3.12, 3.64]])\n",
    "covariance = np.array(\n",
    "    [\n",
    "        [[3.12, 0.2], [0.2, 1]],\n",
    "        [[3.06, -0.87], [-0.87, 2.96]],\n",
    "        [[2.35, -0.38], [-0.38, 2]],\n",
    "        [[1.23, 1.46], [1.46, 3.1]],\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, labels = data_generator(dim, num_classes, num_samples, mean, covariance)\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(\n",
    "    data, labels, test_size=0.33, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Module computes likelihood of train - test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_likelihood(data, labels, mean, covariance):\n",
    "    likelihood = []\n",
    "    for i in range(len(labels)):\n",
    "        j = int(labels[i])\n",
    "        likelihood.append(multivariate_normal.pdf(data[i], mean[j], covariance[j]))\n",
    "\n",
    "    return likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57967c53c8a5429f9c33b22b6c3d330a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "likelihood = calculate_likelihood(train_data, train_labels, mean, covariance)\n",
    "plot_paras = [\"Train set\", [\"o\", \"^\", \"s\", \"p\"], [\"green\", \"red\", \"blue\", \"orange\"]]\n",
    "\n",
    "data_2d_visualize(train_data, train_labels, likelihood, num_classes, plot_paras)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A classifier based on Bayes decision theory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_bayes_classifier(\n",
    "    x, h, dim, covariance_kernel, num_classes, num_samples, data\n",
    "):\n",
    "    prior_probs = calculate_prior_probs(num_samples)\n",
    "    likelihood = [\n",
    "        calculate_PR_estimate(x, h, dim, covariance_kernel, data[i])\n",
    "        for i in range(num_classes)\n",
    "    ]\n",
    "    posterior_probs = [likelihood[i] * prior_probs[i] for i in range(num_classes)]\n",
    "\n",
    "    return posterior_probs.index(max(posterior_probs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group shuffled data into separate parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_train_data = [[] for i in range(num_classes)]\n",
    "\n",
    "for i in range(len(train_labels)):\n",
    "    j = int(train_labels[i])\n",
    "    grouped_train_data[j].append(train_data[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set bandwidth to 1 and choose a standard Gaussian kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = 1\n",
    "covariance_kernel = np.array([[1, 0], [0, 1]])\n",
    "\n",
    "predicted_labels = [\n",
    "    naive_bayes_classifier(\n",
    "        x, h, dim, covariance_kernel, num_classes, num_samples, grouped_train_data\n",
    "    )\n",
    "    for x in test_data\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89083ea9c5cd44a5883288840bef15d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "likelihood = calculate_likelihood(test_data, test_labels, mean, covariance)\n",
    "plot_paras = [\"Test set\", [\"o\", \"^\", \"s\", \"p\"], [\"green\", \"red\", \"blue\", \"orange\"]]\n",
    "\n",
    "data_2d_visualize(test_data, test_labels, likelihood, num_classes, plot_paras)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize predicted set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e21731343b434f16957a548ac035adb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "likelihood = [\n",
    "    calculate_PR_estimate(\n",
    "        test_data[i],\n",
    "        h,\n",
    "        dim,\n",
    "        covariance_kernel,\n",
    "        grouped_train_data[int(predicted_labels[i])],\n",
    "    )\n",
    "    for i in range(len(predicted_labels))\n",
    "]\n",
    "plot_paras = [\"Predicted\", [\"o\", \"^\", \"s\", \"p\"], [\"green\", \"red\", \"blue\", \"orange\"]]\n",
    "\n",
    "data_2d_visualize(test_data, predicted_labels, likelihood, num_classes, plot_paras)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+--------------+--------------+--------------+--------------+\n",
      "|     Test set    | C_0 (actual) | C_1 (actual) | C_2 (actual) | C_3 (actual) |\n",
      "+-----------------+--------------+--------------+--------------+--------------+\n",
      "| C_0 (predicted) |      56      |      1       |      0       |      3       |\n",
      "| C_1 (predicted) |      2       |      56      |      1       |      0       |\n",
      "| C_2 (predicted) |      0       |      0       |      48      |      5       |\n",
      "| C_3 (predicted) |      1       |      1       |      0       |      41      |\n",
      "+-----------------+--------------+--------------+--------------+--------------+\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         C_0       0.95      0.93      0.94        60\n",
      "         C_1       0.97      0.95      0.96        59\n",
      "         C_2       0.98      0.91      0.94        53\n",
      "         C_3       0.84      0.95      0.89        43\n",
      "\n",
      "    accuracy                           0.93       215\n",
      "   macro avg       0.93      0.94      0.93       215\n",
      "weighted avg       0.94      0.93      0.94       215\n",
      "\n"
     ]
    }
   ],
   "source": [
    "conf_mat = metrics.confusion_matrix(test_labels, predicted_labels)\n",
    "\n",
    "conf_table = PrettyTable()\n",
    "\n",
    "temp = [\"C_{} (actual)\".format(i) for i in range(num_classes)]\n",
    "temp.insert(0, \"Test set\")\n",
    "conf_table.field_names = temp\n",
    "\n",
    "for i in range(num_classes):\n",
    "    temp = [int(j) for j in conf_mat[i, :]]\n",
    "    temp.insert(0, \"C_{} (predicted)\".format(i))\n",
    "    conf_table.add_row(temp)\n",
    "\n",
    "print(conf_table)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\n",
    "    metrics.classification_report(\n",
    "        test_labels,\n",
    "        predicted_labels,\n",
    "        target_names=[\"C_{}\".format(i) for i in range(num_classes)],\n",
    "        digits=2,\n",
    "    )\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
